# æ•´ä½“æµç¨‹å›¾ï¼ˆASCIIï¼‰ï¼š
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  ç”¨æˆ·è¾“å…¥query  â”‚
# â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#        â–¼
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ retrieve_node â”‚ â† è°ƒç”¨ensemble_retrieverè·å–RAGæ–‡æ¡£
# â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#        â–¼
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ evaluate_node â”‚ â† LLMè¯„ä¼°æ–‡æ¡£è´¨é‡ï¼Œè¿”å›good/poor
# â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#        â–¼
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚should_web_searchâ”‚ â† æ¡ä»¶åˆ†æ”¯ï¼špoorâ†’web_searchï¼›goodâ†’generate
# â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
#   â–¼       â–¼
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚web_searchâ”‚ â”‚ generateâ”‚
# â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
#      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
#           â–¼
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚  æœ€ç»ˆanswerè¾“å‡º  â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# å¯¼å…¥æ‰€éœ€ç±»å‹ä¸æ¨¡å—
from typing import List,TypedDict
# å¼•å…¥Documentç±»å‹ï¼Œç”¨äºå°è£…æ£€ç´¢åˆ°çš„æ–‡æ¡£
from langchain_core.documents import Document
# å¼•å…¥ChatOpenAIï¼Œç”¨äºè°ƒç”¨å¤§æ¨¡å‹
from langchain_openai import ChatOpenAI
# å¼•å…¥æç¤ºæ¨¡æ¿ï¼Œç”¨äºæ„é€ LLMè¾“å…¥
from langchain_core.prompts import ChatPromptTemplate
# å¼•å…¥å­—ç¬¦ä¸²è¾“å‡ºè§£æå™¨
from langchain_core.output_parsers import StrOutputParser
# å¼•å…¥Google Serperæœç´¢å·¥å…·
from langchain_community.utilities.google_serper import GoogleSerperAPIWrapper
# å¼•å…¥è‡ªå®šä¹‰çš„ensembleæ£€ç´¢å™¨
from documents.retriever_tools import ensemble_retriever
# å¼•å…¥çŠ¶æ€å›¾ä¸ç»“æŸèŠ‚ç‚¹
from langgraph.graph import StateGraph, END

# å¯¼å…¥ç³»ç»Ÿåº“
import os
# å¯¼å…¥dotenvï¼Œç”¨äºè¯»å–æœ¬åœ°.envæ–‡ä»¶
from dotenv import load_dotenv, find_dotenv
# åŠ è½½.envæ–‡ä»¶
load_dotenv(find_dotenv())
# è¯»å–OpenAI APIå¯†é’¥
openai_api_key = os.environ.get("OPENAI_API_KEY")
# è¯»å–OpenAI APIåŸºç¡€åœ°å€
openai_api_base = os.environ.get("OPENAI_API_BASE")
# è¯»å–Serper APIå¯†é’¥
serper_api_key = os.environ.get("SERPER_API_KEY")

# åˆå§‹åŒ–LLMä¸æœç´¢å·¥å…·
try:
    # åˆ›å»ºChatOpenAIå®ä¾‹ï¼Œä½¿ç”¨gpt-4o-miniæ¨¡å‹ï¼Œtemperature=0ç¡®ä¿ç¡®å®šæ€§
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.0, openai_api_key=openai_api_key, openai_api_base=openai_api_base)
    # åˆ›å»ºGoogleSerperæœç´¢å·¥å…·å®ä¾‹
    web_search_tool = GoogleSerperAPIWrapper(api_key=serper_api_key) 
except Exception as e:
    # å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼Œæ‰“å°å¼‚å¸¸å¹¶æç¤ºæ£€æŸ¥ç¯å¢ƒå˜é‡
    print(e)
    print("è¯·æ£€æŸ¥ç¯å¢ƒå˜é‡ OPENAI_API_KEY å’Œ SERPER_API_KEY æ˜¯å¦æ­£ç¡®è®¾ç½®ã€‚")

# å®šä¹‰ä¸€ä¸ªå›¾çŠ¶æ€ç±»ï¼Œç”¨äºåœ¨å›¾èŠ‚ç‚¹é—´ä¼ é€’æ•°æ®
class GraphState(TypedDict):
    """A state of the graph."""
    query: str  # ç”¨æˆ·æŸ¥è¯¢
    documents: List[Document]  # æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
    context_quality: str  # æ–‡æ¡£è´¨é‡è¯„ä¼°ç»“æœ
    answer: str  # æœ€ç»ˆç”Ÿæˆçš„ç­”æ¡ˆ

# å®šä¹‰retrieveèŠ‚ç‚¹ï¼šè´Ÿè´£ä»RAGçŸ¥è¯†åº“ä¸­æ£€ç´¢æ–‡æ¡£
def retrieve_node(state: GraphState):
    # æ‰“å°èŠ‚ç‚¹å¼€å§‹ä¿¡æ¯
    print("1.æ­£åœ¨RAGæ£€ç´¢èŠ‚ç‚¹...")
    # ä»çŠ¶æ€ä¸­è·å–ç”¨æˆ·æŸ¥è¯¢
    query = state["query"]
    
    # ç›´æ¥è°ƒç”¨ensemble_retrieverï¼Œè¿”å›List[Document]
    documents = ensemble_retriever.invoke(query) 
    
    # æ‰“å°æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡
    print(f"æ£€ç´¢åˆ° {len(documents)} ç¯‡ RAG æ–‡æ¡£")
    # è¿”å›æ›´æ–°åçš„æ–‡æ¡£åˆ—è¡¨
    return {"documents": documents}

# å®šä¹‰evaluateèŠ‚ç‚¹ï¼šä½¿ç”¨LLMè¯„ä¼°æ£€ç´¢åˆ°çš„æ–‡æ¡£è´¨é‡
def evaluate_node(state:GraphState):
    """
    ä½¿ç”¨LLMè¯„ä¼°èŠ‚ç‚¹è´¨é‡
    """
    # æ‰“å°èŠ‚ç‚¹å¼€å§‹ä¿¡æ¯
    print("2.æ­£åœ¨è¯„ä¼°èŠ‚ç‚¹è´¨é‡...")
    # ä»çŠ¶æ€ä¸­è·å–æŸ¥è¯¢ä¸æ–‡æ¡£
    query = state["query"]
    documents = state["documents"]

    # å¦‚æœæ–‡æ¡£ä¸ºç©ºï¼Œç›´æ¥è¿”å›poor
    if not documents: # å¦‚æœæ²¡æœ‰æ–‡æ¡£ï¼Œåˆ™è¿”å› "æ— "
        print("æ— æ–‡æ¡£")
        return {"context_quality": "poor"}
    # å®šä¹‰è¯„ä¼°æç¤ºæ¨¡æ¿
    eval_prompt_template = """
    ç»™å®šä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢å’Œä¸€ç»„æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼š

    æŸ¥è¯¢: {query}

    æ–‡æ¡£:
    {documents}

    è¯·è¯„ä¼°è¿™äº›æ–‡æ¡£æ˜¯å¦è¶³å¤Ÿã€ç›¸å…³ä¸”é«˜è´¨é‡ï¼Œè¶³ä»¥å›ç­”è¯¥æŸ¥è¯¢ã€‚
    ä½ åªéœ€è¦å›ç­”ä¸¤ä¸ªè¯ä¸­çš„ä¸€ä¸ªï¼š
    - 'good' (å¦‚æœæ–‡æ¡£è¶³å¤Ÿå¥½)
    - 'poor' (å¦‚æœæ–‡æ¡£ä¸ç›¸å…³ã€ä¸å……åˆ†æˆ–è´¨é‡ä½ä¸‹)
    """
    # åˆ›å»ºæç¤ºæ¨¡æ¿å¯¹è±¡
    eval_prompt = ChatPromptTemplate.from_template(eval_prompt_template)
    # å®šä¹‰å‡½æ•°ï¼šå°†æ–‡æ¡£åˆ—è¡¨æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²
    def format_docs_for_prompt(docs: List[Document]) -> str:
       return "\n\n".join(f"--- Doc {i+1} ---\n{doc.page_content}" for i, doc in enumerate(docs)) 
    # æ„å»ºè¯„ä¼°é“¾ï¼šæç¤º | LLM | è¾“å‡ºè§£æ
    eval_chain = eval_prompt | llm | StrOutputParser()
    # æ ¼å¼åŒ–æ–‡æ¡£
    formatted_docs = format_docs_for_prompt(documents)
    # è°ƒç”¨è¯„ä¼°é“¾è·å–è´¨é‡ç»“æœ
    quality = eval_chain.invoke({"query": query, "documents": formatted_docs})
    # æ ¹æ®è¿”å›å­—ç¬¦ä¸²åˆ¤æ–­æœ€ç»ˆè´¨é‡
    quality_decision = "poor" if "poor" in quality.lower() else "good"
    # æ‰“å°è¯„ä¼°ç»“æœ
    print(f"è¯„ä¼°ç»“æœ: {quality_decision}")
    # è¿”å›è´¨é‡ç»“æœ
    return {"context_quality": quality_decision}

# å®šä¹‰web_searchèŠ‚ç‚¹ï¼šå½“RAGè´¨é‡ä¸ºpooræ—¶ï¼Œæ‰§è¡Œç½‘é¡µæœç´¢è¡¥å……æ–‡æ¡£
def web_search_node(state: GraphState):
    """
    å¦‚æœ RAG è´¨é‡ 'poor'ï¼Œåˆ™æ‰§è¡Œæ­¤èŠ‚ç‚¹è¿›è¡Œç½‘é¡µæœç´¢ã€‚
    """
    # æ‰“å°èŠ‚ç‚¹å¼€å§‹ä¿¡æ¯
    print("--- 3. (ä¿®æ­£) èŠ‚ç‚¹ï¼šæ‰§è¡Œç½‘é¡µæœç´¢ ---")
    # ä»çŠ¶æ€ä¸­è·å–ç”¨æˆ·æŸ¥è¯¢
    query = state["query"]
    
    # è°ƒç”¨Serperæœç´¢å·¥å…·è·å–ç»“æœ
    search_results = web_search_tool.results(query) 
    
    # åˆå§‹åŒ–ç½‘é¡µæ–‡æ¡£åˆ—è¡¨
    web_docs = []
    # å¦‚æœæœç´¢ç»“æœä¸­æœ‰organicå­—æ®µ
    if "organic" in search_results:
        # ä»…é€‰æ‹©å‰3ä¸ªç»“æœ
        for result in search_results["organic"][:3]:
            # å°è£…ä¸ºDocumentå¯¹è±¡
            web_docs.append(Document(
                page_content=result.get("snippet", "No snippet available"),
                metadata={
                    "source": result.get("link", "N/A"),
                    "title": result.get("title", "N/A"),
                    "source_type": "web" # æ ‡è®°ä¸ºç½‘é¡µæ¥æº
                }
            ))
    
    # æ‰“å°ç½‘é¡µæœç´¢åˆ°çš„æ–‡æ¡£æ•°é‡
    print(f"ç½‘é¡µæœç´¢åˆ° {len(web_docs)} ç¯‡æ–°æ–‡æ¡£")
    
    # å°†ç½‘é¡µæœç´¢ç»“æœè¿½åŠ åˆ°åŸæœ‰RAGæ–‡æ¡£åˆ—è¡¨
    all_documents = state["documents"] + web_docs
    
    # è¿”å›åˆå¹¶åçš„æ–‡æ¡£åˆ—è¡¨
    return {"documents": all_documents} # ç”¨åˆå¹¶åçš„åˆ—è¡¨è¦†ç›–çŠ¶æ€

# å®šä¹‰generateèŠ‚ç‚¹ï¼šåˆ©ç”¨æœ€ç»ˆæ–‡æ¡£åˆ—è¡¨ç”Ÿæˆç­”æ¡ˆ
def generate_node(state: GraphState):
    """
    ä½¿ç”¨æœ€ç»ˆçš„æ–‡æ¡£åˆ—è¡¨ (RAG æˆ– RAG + Web) æ¥ç”Ÿæˆç­”æ¡ˆã€‚
    """
    # æ‰“å°èŠ‚ç‚¹å¼€å§‹ä¿¡æ¯
    print("--- 4. èŠ‚ç‚¹ï¼šç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ ---")
    # ä»çŠ¶æ€ä¸­è·å–æŸ¥è¯¢ä¸æ–‡æ¡£
    query = state["query"]
    documents = state["documents"]

    # å®šä¹‰ç”Ÿæˆæç¤ºæ¨¡æ¿
    gen_prompt_template = """
    ä½ æ˜¯ä¸€ä¸ªå…³äºåŠå¯¼ä½“å’ŒèŠ¯ç‰‡çš„ä¸“å®¶åŠ©æ‰‹ã€‚
    è¯·ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å…¨é¢å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
    å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ï¼Œè¯·æ ¹æ®ä½ çš„çŸ¥è¯†åº“å›ç­”ï¼Œä½†è¦è¯´æ˜ä¸Šä¸‹æ–‡æœªæä¾›æ­¤ä¿¡æ¯ã€‚

    ä¸Šä¸‹æ–‡ (å¯èƒ½åŒ…å«çŸ¥è¯†åº“å’Œç½‘é¡µæœç´¢ç»“æœ):
    {context}

    é—®é¢˜: {query}

    å›ç­”:
    """
    # åˆ›å»ºç”Ÿæˆæç¤ºæ¨¡æ¿å¯¹è±¡
    gen_prompt = ChatPromptTemplate.from_template(gen_prompt_template)

    # å®šä¹‰å‡½æ•°ï¼šå°†æ–‡æ¡£åˆ—è¡¨æ ¼å¼åŒ–ä¸ºå¸¦æ¥æºçš„å­—ç¬¦ä¸²
    def format_context_for_gen(docs: List[Document]) -> str:
         return "\n\n".join(
            f"--- æ¥æº: {doc.metadata.get('source', 'N/A')} (ç±»å‹: {doc.metadata.get('source_type', 'RAG')}) ---\n{doc.page_content}" 
            for doc in docs
        )
    def format_context_for_gen(docs: List[Document]) -> str:
        return "\n\n".join(
            f"--- æ¥æº: {doc.metadata.get('source', 'N/A')} (ç±»å‹: {doc.metadata.get('source_type', 'RAG')}) ---\n{doc.page_content}" 
            for doc in docs
        )

    # --- ä»¥ä¸‹æ˜¯è¡¥å…¨çš„éƒ¨åˆ† ---
    
    # æ„å»ºç”Ÿæˆé“¾ï¼šæç¤º | LLM | è¾“å‡ºè§£æ
    rag_chain = gen_prompt | llm | StrOutputParser()
    
    # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
    formatted_context = format_context_for_gen(documents)
    
    # ç”Ÿæˆç­”æ¡ˆ
    answer = rag_chain.invoke({"context": formatted_context, "query": query})
    
    # æ‰“å°ç­”æ¡ˆç‰‡æ®µ
    print(f"ç”Ÿæˆçš„ç­”æ¡ˆç‰‡æ®µ: {answer[:50]}...")
    
    # è¿”å›æœ€ç»ˆç­”æ¡ˆ
    return {"answer": answer}

# ==========================================
# 5. æ„å»º LangGraph å·¥ä½œæµ
# ==========================================

# å®šä¹‰æ¡ä»¶åˆ†æ”¯é€»è¾‘ï¼šæ ¹æ®è¯„ä¼°ç»“æœå†³å®šä¸‹ä¸€æ­¥
def decide_to_web_search(state: GraphState):
    """
    æ ¹æ®è¯„ä¼°èŠ‚ç‚¹çš„ context_quality å†³å®šä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚
    """
    print("--- æ£€æµ‹æ˜¯å¦éœ€è¦ç½‘é¡µæœç´¢ ---")
    quality = state["context_quality"]
    
    if quality == "poor":
        print("è¯„ä¼°ç»“æœä¸º poor -> è½¬å‘ç½‘é¡µæœç´¢ (web_search)")
        return "web_search"
    else:
        print("è¯„ä¼°ç»“æœä¸º good -> ç›´æ¥ç”Ÿæˆç­”æ¡ˆ (generate)")
        return "generate"

# åˆå§‹åŒ–çŠ¶æ€å›¾
workflow = StateGraph(GraphState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("retrieve", retrieve_node)
workflow.add_node("evaluate", evaluate_node)
workflow.add_node("web_search", web_search_node)
workflow.add_node("generate", generate_node)

# å®šä¹‰è¾¹çš„è¿æ¥é€»è¾‘
# 1. èµ·ç‚¹ -> æ£€ç´¢
workflow.set_entry_point("retrieve")

# 2. æ£€ç´¢ -> è¯„ä¼°
workflow.add_edge("retrieve", "evaluate")

# 3. è¯„ä¼° -> æ¡ä»¶åˆ†æ”¯ (web_search æˆ– generate)
workflow.add_conditional_edges(
    "evaluate",               # ä¸Šä¸€ä¸ªèŠ‚ç‚¹
    decide_to_web_search,     # å†³ç­–å‡½æ•°
    {                         # æ˜ å°„å…³ç³»ï¼šå‡½æ•°è¿”å›å€¼ -> ä¸‹ä¸€ä¸ªèŠ‚ç‚¹å
        "web_search": "web_search",
        "generate": "generate"
    }
)

# 4. ç½‘é¡µæœç´¢ -> ç”Ÿæˆ (æœç´¢è¡¥å…¨åï¼Œå¿…é¡»å»ç”Ÿæˆ)
workflow.add_edge("web_search", "generate")

# 5. ç”Ÿæˆ -> ç»“æŸ
workflow.add_edge("generate", END)

# ç¼–è¯‘å›¾ï¼ˆç”Ÿæˆå¯æ‰§è¡Œçš„ Runnableï¼‰
app = workflow.compile()

# ==========================================
# 6. æ‰§è¡Œè°ƒç”¨ (Main å‡½æ•°)
# ==========================================

if __name__ == "__main__":
    import pprint
    
    # æµ‹è¯•é—®é¢˜
    # query = "ä»€ä¹ˆæ˜¯ GAA æ™¶ä½“ç®¡æŠ€æœ¯ï¼Ÿ"  # è¿™ä¸ªå¯èƒ½ç›´æ¥èµ° RAG
    query = "2024å¹´å°ç§¯ç”µçš„æœ€æ–°3nmäº§èƒ½æƒ…å†µå¦‚ä½•ï¼Ÿ" # è¿™ä¸ªå¯èƒ½éœ€è¦èµ° Web Search (å¦‚æœçŸ¥è¯†åº“æ²¡æ›´æ–°)
    
    print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œ Agentic RAGï¼Œé—®é¢˜ï¼š{query}\n" + "="*50)
    
    # è¿è¡Œå›¾
    inputs = {"query": query}
    
    # app.invoke ä¼šè¿”å›æœ€ç»ˆçš„çŠ¶æ€å­—å…¸
    try:
        final_state = app.invoke(inputs)
        
        print("\n" + "="*50)
        print("âœ… æ‰§è¡Œå®Œæˆï¼æœ€ç»ˆç­”æ¡ˆï¼š\n")
        print(final_state["answer"])
        print("\n" + "="*50)
        
        # (å¯é€‰) æ‰“å°ä½¿ç”¨çš„æ–‡æ¡£æ¥æºï¼Œç¡®è®¤æ˜¯å¦ç”¨äº†ç½‘é¡µæœç´¢
        print("ğŸ“š å‚è€ƒæ–‡æ¡£æ¥æºï¼š")
        for i, doc in enumerate(final_state.get("documents", [])):
           source = doc.metadata.get("source", "Unknown")
           type_ = doc.metadata.get("source_type", "RAG")
           print(f"{i+1}. [{type_}] {source}")
            
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")