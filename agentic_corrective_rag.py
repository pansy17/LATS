import os
import math
import ast
import operator
from typing import List, TypedDict, Optional, Dict, Any, Union

# ----------------- LangChain / LangGraph Imports -----------------
from langchain_core.documents import Document
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.utilities.google_serper import GoogleSerperAPIWrapper
from langgraph.graph import StateGraph, END

# ----------------- ç³»ç»Ÿä¸ç¯å¢ƒé…ç½® -----------------
from dotenv import load_dotenv, find_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(find_dotenv())
openai_api_key = os.environ.get("OPENAI_API_KEY")
openai_api_base = os.environ.get("OPENAI_API_BASE")
serper_api_key = os.environ.get("SERPER_API_KEY")

# ----------------- ç”¨æˆ·è‡ªå®šä¹‰å·¥å…·å¯¼å…¥ -----------------
# æ³¨æ„ï¼šè¿™é‡Œç›´æ¥ä½¿ç”¨æ‚¨æä¾›çš„æ£€ç´¢å™¨
try:
    from documents.retriever_tools import ensemble_retriever
    print("âœ… æˆåŠŸåŠ è½½æœ¬åœ° RAG æ£€ç´¢å™¨: ensemble_retriever")
except ImportError:
    raise ImportError("âŒ æœªæ‰¾åˆ° documents.retriever_tools æ¨¡å—ï¼Œè¯·ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®ã€‚")

# ----------------- å…¨å±€å·¥å…·åˆå§‹åŒ– -----------------
try:
    # ä½¿ç”¨ gpt-4o-miniï¼Œtemperature è®¾ç½®ä¸º 1.0 ä»¥å¢åŠ æ ‘æœç´¢çš„åˆ›é€ æ€§ï¼ˆMCTS éœ€è¦ä¸€å®šçš„éšæœºæ€§æ¥æ‰©å±•ä¸åŒè·¯å¾„ï¼‰
    # å¦‚æœæ‚¨éœ€è¦æå…¶ä¸¥æ ¼çš„è¾“å‡ºï¼Œå¯ä»¥åœ¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆæ—¶è°ƒæ•´å› 0
    llm = ChatOpenAI(
        model="gpt-4o-mini", 
        temperature=0.7, 
        openai_api_key=openai_api_key, 
        openai_api_base=openai_api_base
    )
    
    # ç½‘é¡µæœç´¢å·¥å…·
    web_search_tool = GoogleSerperAPIWrapper(api_key=serper_api_key)
    print("âœ… æˆåŠŸåˆå§‹åŒ– Google Serper å·¥å…·")
    
except Exception as e:
    print(f"âŒ å·¥å…·åˆå§‹åŒ–å¤±è´¥: {e}")
    exit(1)


# ==========================================
# 1. MCTS æ ¸å¿ƒæ•°æ®ç»“æ„ (Node & State)
# ==========================================

class MCTSNode:
    """è’™ç‰¹å¡æ´›æ ‘æœç´¢èŠ‚ç‚¹"""
    def __init__(self, parent=None, action_thought: str = "Root"):
        self.parent: Optional[MCTSNode] = parent
        self.children: List[MCTSNode] = []
        
        # èŠ‚ç‚¹å±æ€§
        self.action_thought = action_thought  # å½“å‰èŠ‚ç‚¹çš„â€œæƒ³æ³•â€æˆ–â€œå­æŸ¥è¯¢â€
        self.content: str = ""                # æ‰§è¡Œæ£€ç´¢/æœç´¢åçš„ç»“æœå†…å®¹
        self.visits: int = 0                  # è®¿é—®æ¬¡æ•° N
        self.value_sum: float = 0.0           # ç´¯è®¡åˆ†æ•° V
        self.depth: int = 0 if parent is None else parent.depth + 1
        
    @property# è®¡ç®—å¹³å‡ä»·å€¼ï¼Œé€šè¿‡ç´¯è®¡åˆ†æ•° V å’Œè®¿é—®æ¬¡æ•° N è®¡ç®—
    def value(self) -> float:
        """å¹³å‡ä»·å€¼ Q(s, a)"""
        if self.visits == 0:
            return 0.0
        return self.value_sum / self.visits

    def uct_score(self, parent_visits: int, c_puct: float = 1.41) -> float:
        """è®¡ç®— UCT (Upper Confidence Bound for Trees) åˆ†æ•°"""
        if self.visits == 0:
            return float('inf')  # ä¼˜å…ˆè®¿é—®æœªè®¿é—®è¿‡çš„èŠ‚ç‚¹
        
        q_value = self.value
        # U é¡¹ï¼šæ¢ç´¢å› å­
        u_value = c_puct * math.sqrt(math.log(parent_visits) / (1 + self.visits))
        return q_value + u_value

    def add_child(self, child_node):
        self.children.append(child_node)

    def __repr__(self):
        return f"<Node depth={self.depth} visits={self.visits} val={self.value:.2f} thought='{self.action_thought}'>"

class TreeState(TypedDict):
    """LangGraph çŠ¶æ€å®šä¹‰"""
    original_query: str     # ç”¨æˆ·åŸå§‹é—®é¢˜
    root: MCTSNode          # æ ‘æ ¹
    current_node: MCTSNode  # å½“å‰æ­£åœ¨å¤„ç†çš„èŠ‚ç‚¹
    iterations: int         # å½“å‰è¿­ä»£è½®æ•°
    max_iterations: int     # æœ€å¤§è¿­ä»£è½®æ•°ï¼ˆé¢„ç®—ï¼‰
    best_answer: str        # æœ€ç»ˆç”Ÿæˆçš„ç­”æ¡ˆ

# ==========================================
# 2. LATS æ ¸å¿ƒèŠ‚ç‚¹é€»è¾‘ (Nodes)
# ==========================================

def initial_node(state: TreeState):
    """ã€åˆå§‹åŒ–ã€‘åˆ›å»ºæ ¹èŠ‚ç‚¹"""
    print(f"\nğŸŒ± [Start] åˆå§‹åŒ– LATS æ ‘æœç´¢ï¼ŒåŸé—®é¢˜: {state['original_query']}")
    root = MCTSNode(action_thought=state['original_query'])
    # æ ¹èŠ‚ç‚¹ä¸éœ€è¦å†…å®¹ï¼Œåªæ˜¯èµ·ç‚¹
    return {"root": root, "current_node": root, "iterations": 0}

def selection_node(state: TreeState):
    """ã€é€‰æ‹©ã€‘åŸºäº UCT é€‰æ‹©æœ€æœ‰æ½œåŠ›çš„å¶å­èŠ‚ç‚¹"""
    root = state["root"]
    node = root
    
    # è´ªå©ªé€‰æ‹©ç›´åˆ°å¶å­èŠ‚ç‚¹ï¼ˆæ²¡æœ‰å­©å­çš„èŠ‚ç‚¹ï¼‰
    while node.children:
        # é€‰æ‹© UCT åˆ†æ•°æœ€é«˜çš„å­èŠ‚ç‚¹
        node = max(node.children, key=lambda c: c.uct_score(node.visits))
    
    return {"current_node": node}

def expansion_node(state: TreeState):
    """ã€æ‰©å±•ã€‘LLM ç”Ÿæˆæ–°çš„å­æŸ¥è¯¢æˆ–æ€è€ƒæ­¥éª¤"""
    current_node = state["current_node"]
    query = current_node.action_thought
    
    # å¦‚æœèŠ‚ç‚¹å·²ç»è®¿é—®è¿‡ï¼ˆsimulationè¿‡ï¼‰ï¼Œæˆ–è€…å®ƒæ˜¯æ ¹èŠ‚ç‚¹ï¼Œæˆ‘ä»¬éœ€è¦æ‰©å±•å‡ºæ–°çš„å­èŠ‚ç‚¹
    # é™åˆ¶æ·±åº¦ï¼Œé˜²æ­¢æ— é™é€’å½’ï¼Œä¾‹å¦‚æ·±åº¦è¶…è¿‡3å°±ä¸å†æ‰©å±•
    if (current_node.visits > 0 or current_node.depth == 0) and current_node.depth < 3:
        print(f"ğŸŒ² [Expand] æ­£åœ¨æ‰©å±•èŠ‚ç‚¹: '{query[:20]}...'")
        
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“å®¶ç ”ç©¶å‘˜ã€‚é’ˆå¯¹é—®é¢˜: "{query}"
        è¯·ç”Ÿæˆ 2 åˆ° 3 ä¸ª ä¸åŒçš„ã€å…·ä½“çš„æœç´¢å­æŸ¥è¯¢ï¼Œä»¥ä¾¿ä»ä¸åŒè§’åº¦è·å–ä¿¡æ¯æ¥å›ç­”åŸé—®é¢˜ã€‚
        
        è¦æ±‚ï¼š
        1. å­æŸ¥è¯¢åº”è¯¥äº’è¡¥ï¼Œè¦†ç›–ä¸åŒæ–¹é¢ï¼ˆä¾‹å¦‚ï¼šå®šä¹‰ã€æœ€æ–°æ•°æ®ã€æŠ€æœ¯ç»†èŠ‚ï¼‰ã€‚
        2. ä¸¥æ ¼è¿”å› Python åˆ—è¡¨æ ¼å¼å­—ç¬¦ä¸²ã€‚
        
        ç¤ºä¾‹æ ¼å¼: ["æŸ¥è¯¢A", "æŸ¥è¯¢B", "æŸ¥è¯¢C"]
        """
        try:
            response = llm.invoke(prompt).content
            # ç®€å•çš„è§£æé€»è¾‘
            start = response.find('[')
            end = response.rfind(']') + 1
            sub_queries = ast.literal_eval(response[start:end])
        except Exception as e:
            print(f"âš ï¸ è§£ææ‰©å±•æŸ¥è¯¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥: {e}")
            sub_queries = [f"{query} details", f"{query} statistics"]

        # åˆ›å»ºå­èŠ‚ç‚¹å¹¶æŒ‚è½½
        if not sub_queries:
            sub_queries = [query] # Fallback

        for q in sub_queries:
            child = MCTSNode(parent=current_node, action_thought=q)
            current_node.add_child(child)
        
        # æ‰©å±•åï¼Œç«‹å³é€‰æ‹©ç¬¬ä¸€ä¸ªæ–°å­èŠ‚ç‚¹è¿›å…¥ Simulation
        if current_node.children:
            return {"current_node": current_node.children[0]}
    
    # å¦‚æœæ— æ³•æ‰©å±•æˆ–æ— éœ€æ‰©å±•ï¼Œä¿æŒå½“å‰èŠ‚ç‚¹
    return {"current_node": current_node}

def simulation_node(state: TreeState):
    """ã€æ¨¡æ‹Ÿã€‘æ‰§è¡ŒçœŸå®çš„ RAG å’Œ Web Search"""
    node = state["current_node"]
    
    # å¦‚æœèŠ‚ç‚¹å·²æœ‰å†…å®¹ï¼ˆå·²è¢«æ¨¡æ‹Ÿè¿‡ï¼‰ï¼Œåˆ™è·³è¿‡
    if node.content:
        return {"current_node": node}
        
    query = node.action_thought
    print(f"ğŸ” [Simulate] æ‰§è¡ŒçœŸå®æ£€ç´¢: {query}")
    
    combined_content = ""
    
    # 1. æ‰§è¡Œ RAG æ£€ç´¢ (Local Knowledge)
    try:
        rag_docs = ensemble_retriever.invoke(query)
        if rag_docs:
            rag_text = "\n".join([d.page_content for d in rag_docs[:2]]) # å–å‰2æ¡æœ€ç›¸å…³çš„
            combined_content += f"ã€æœ¬åœ°çŸ¥è¯†åº“ã€‘:\n{rag_text}\n"
            print(f"   -> RAG æ£€ç´¢åˆ° {len(rag_docs)} æ¡æ–‡æ¡£")
    except Exception as e:
        print(f"   -> RAG æ£€ç´¢å‡ºé”™: {e}")

    # 2. æ‰§è¡Œ Web Search (External Knowledge)
    # LATS çš„ä¼˜åŠ¿ï¼šå¯ä»¥åŒæ—¶ç»“åˆæœ¬åœ°å’Œç½‘ç»œ
    try:
        web_res = web_search_tool.results(query)
        if "organic" in web_res:
            web_text = ""
            for item in web_res["organic"][:2]: # å–å‰2æ¡
                web_text += f"- {item.get('title')}: {item.get('snippet')}\n"
            combined_content += f"ã€ç½‘ç»œæœç´¢ã€‘:\n{web_text}\n"
            print(f"   -> Web æœç´¢åˆ° {len(web_res.get('organic', []))} æ¡ç»“æœ")
    except Exception as e:
        print(f"   -> Web æœç´¢å‡ºé”™: {e}")

    if not combined_content:
        combined_content = "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"

    node.content = combined_content
    return {"current_node": node}

def evaluation_node(state: TreeState):
    """ã€è¯„ä¼° & åå‘ä¼ æ’­ã€‘LLM å¯¹å½“å‰èŠ‚ç‚¹å†…å®¹æ‰“åˆ†ï¼Œå¹¶æ›´æ–°è·¯å¾„"""
    node = state["current_node"]
    original_query = state["original_query"]
    content = node.content
    
    print(f"âš–ï¸ [Evaluate] æ­£åœ¨è¯„ä¼°èŠ‚ç‚¹è´¨é‡...")
    
    # æ„é€ è¯„åˆ† Prompt
    eval_prompt = f"""
    ç”¨æˆ·é—®é¢˜: {original_query}
    å½“å‰èŠ‚ç‚¹çš„å­æŸ¥è¯¢: {node.action_thought}
    æ£€ç´¢åˆ°çš„å†…å®¹:
    {content[:2000]} (æˆªå–)
    
    è¯·å¯¹ä¸Šè¿°å†…å®¹å¯¹äºå›ç­”ç”¨æˆ·é—®é¢˜çš„æœ‰ç”¨æ€§è¿›è¡Œæ‰“åˆ† (0.0 åˆ° 1.0)ã€‚
    1.0 è¡¨ç¤ºå®Œç¾åŒ…å«ç­”æ¡ˆï¼Œ0.0 è¡¨ç¤ºå®Œå…¨æ— å…³ã€‚
    
    è¯·åªè¿”å›ä¸€ä¸ªæ•°å­—ï¼Œä¾‹å¦‚: 0.8
    """
    
    score = 0.5 # é»˜è®¤ä¸­ç«‹åˆ†
    try:
        response = llm.invoke(eval_prompt).content.strip()
        # æå–æ•°å­—
        import re
        match = re.search(r"0\.\d+|1\.0|0|1", response)
        if match:
            score = float(match.group())
    except Exception as e:
        print(f"   -> è¯„åˆ†å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åˆ†: {e}")

    print(f"   -> è¯„åˆ†ç»“æœ: {score}")

    # --- Backpropagation (åå‘ä¼ æ’­) ---
    # ä»å½“å‰èŠ‚ç‚¹ä¸€ç›´å›æº¯åˆ°æ ¹èŠ‚ç‚¹ï¼Œæ›´æ–° visits å’Œ value_sum
    temp_node = node
    while temp_node:
        temp_node.visits += 1
        temp_node.value_sum += score
        temp_node = temp_node.parent
        
    return {"iterations": state["iterations"] + 1}

def generation_node(state: TreeState):
    """ã€ç”Ÿæˆã€‘æ±‡æ€»æœ€ä½³è·¯å¾„ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"""
    print("\nâœï¸ [Generate] æœç´¢ç»“æŸï¼Œæ­£åœ¨ç”Ÿæˆæœ€ç»ˆå›ç­”...")
    root = state["root"]
    original_query = state["original_query"]
    
    # ç­–ç•¥ï¼šæ”¶é›†æ ‘ä¸­ visits æ¬¡æ•°æœ€å¤šçš„è·¯å¾„ï¼ˆæˆ–è€…åˆ†æ•°æœ€é«˜çš„è·¯å¾„ï¼‰
    # è¿™é‡Œæˆ‘ä»¬éå†ä¸€å±‚ï¼ŒæŠŠæ‰€æœ‰æ¢ç´¢è¿‡çš„å†…å®¹éƒ½ä½œä¸ºä¸Šä¸‹æ–‡ï¼ˆåªè¦åˆ†æ•°å°šå¯ï¼‰
    
    all_contexts = []
    
    def collect_contexts(node: MCTSNode):
        # ç®€å•çš„éå†æ”¶é›†é€»è¾‘ï¼Œæ”¶é›† value > 0.4 çš„èŠ‚ç‚¹å†…å®¹
        if node.visits > 0 and node.value > 0.4 and node.content:
             all_contexts.append(f"å­æŸ¥è¯¢: {node.action_thought}\nå†…å®¹: {node.content}")
        for child in node.children:
            collect_contexts(child)
            
    collect_contexts(root)
    
    # å»é‡å¹¶æ‹¼æ¥
    unique_contexts = "\n---\n".join(list(set(all_contexts))[:5]) # é™åˆ¶é•¿åº¦é˜²æ­¢ Context Window æº¢å‡º
    
    if not unique_contexts:
        unique_contexts = "æœªæ£€ç´¢åˆ°æœ‰æ•ˆä¿¡æ¯ã€‚"

    final_prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªåŠå¯¼ä½“è¡Œä¸šä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹ç»è¿‡éªŒè¯çš„å¤šæ­¥æ£€ç´¢ä¿¡æ¯ï¼Œå›ç­”ç”¨æˆ·é—®é¢˜ã€‚
    
    ç”¨æˆ·é—®é¢˜: {original_query}
    
    === æ£€ç´¢ä¸Šä¸‹æ–‡ ===
    {unique_contexts}
    ==================
    
    è¯·è¾“å‡ºé€»è¾‘æ¸…æ™°ã€å¼•ç”¨æ˜ç¡®çš„æœ€ç»ˆå›ç­”ï¼š
    """
    
    final_answer = llm.invoke(final_prompt).content
    return {"best_answer": final_answer}

# ==========================================
# 3. è·¯ç”±é€»è¾‘ (Conditional Edges)
# ==========================================

def should_continue(state: TreeState):
    """åˆ¤æ–­æ˜¯ç»§ç»­æœç´¢è¿˜æ˜¯ç”Ÿæˆç­”æ¡ˆ"""
    if state["iterations"] < state["max_iterations"]:
        return "selection"
    return "generate"

# ==========================================
# 4. æ„å»º LangGraph å·¥ä½œæµ
# ==========================================

workflow = StateGraph(TreeState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("initial", initial_node)
workflow.add_node("selection", selection_node)
workflow.add_node("expansion", expansion_node)
workflow.add_node("simulation", simulation_node)
workflow.add_node("evaluation", evaluation_node)
workflow.add_node("generate", generation_node)

# è®¾ç½®è¾¹
workflow.set_entry_point("initial")
workflow.add_edge("initial", "selection")
workflow.add_edge("selection", "expansion")
workflow.add_edge("expansion", "simulation")
workflow.add_edge("simulation", "evaluation")

# æ¡ä»¶è¾¹ï¼šEvaluation ç»“æŸåï¼Œåˆ¤æ–­æ˜¯å¦è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°
workflow.add_conditional_edges(
    "evaluation",
    should_continue,
    {
        "selection": "selection", # å¾ªç¯ç»§ç»­æœç´¢
        "generate": "generate"    # ç»“æŸæœç´¢ï¼Œç”Ÿæˆç­”æ¡ˆ
    }
)

workflow.add_edge("generate", END)

# ç¼–è¯‘åº”ç”¨
app = workflow.compile()

# ==========================================
# 5. ä¸»ç¨‹åºæ‰§è¡Œå…¥å£
# ==========================================

if __name__ == "__main__":
    # æµ‹è¯•é—®é¢˜ï¼šè¿™æ˜¯ä¸€ä¸ªå¤æ‚é—®é¢˜ï¼Œå•æ¬¡æ£€ç´¢å¯èƒ½ä¸å…¨ï¼Œé€‚åˆ MCTS
    query = "2024å¹´å°ç§¯ç”µçš„æœ€æ–°3nmäº§èƒ½æƒ…å†µå¦‚ä½•ï¼Ÿè‹¹æœå’Œè‹±ä¼Ÿè¾¾çš„è®¢å•å æ¯”å¤§æ¦‚æ˜¯å¤šå°‘ï¼Ÿ"
    
    print(f"ğŸš€ [Agent Start] å¯åŠ¨ LATS Agentic RAG")
    print(f"â“ é—®é¢˜: {query}\n" + "="*50)
    
    # è¿™é‡Œçš„ max_iterations å†³å®šäº†æœç´¢çš„å¹¿åº¦å’Œæ·±åº¦ï¼ˆå°è¯•å¤šå°‘æ¬¡èŠ‚ç‚¹æ‰©å±•ï¼‰
    # å»ºè®®è®¾ç½®ä¸º 5-10 æ¬¡ï¼Œä¸ºäº†æ¼”ç¤ºé€Ÿåº¦è¿™é‡Œè®¾ä¸º 4
    inputs = {
        "original_query": query, 
        "max_iterations": 10
    }
    
    try:
        final_state = app.invoke(inputs)
        
        print("\n" + "="*50)
        print("âœ… [Done] æœ€ç»ˆç­”æ¡ˆï¼š\n")
        print(final_state["best_answer"])
        print("\n" + "="*50)
        
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()