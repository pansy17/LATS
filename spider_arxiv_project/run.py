# run.py
from scrapy.crawler import CrawlerProcess
from scrapy.utils.project import get_project_settings
import os

# ç¡®ä¿èƒ½æ‰¾åˆ° settings
os.environ.setdefault('SCRAPY_SETTINGS_MODULE', 'simple_bot.settings')

if __name__ == "__main__":
    print("=== ğŸš€ å¯åŠ¨ç®€æ˜“ç‰ˆåŠå¯¼ä½“çˆ¬è™« ===")
    
    # åŠ è½½ settings.py çš„é…ç½®
    settings = get_project_settings()
    process = CrawlerProcess(settings)
    
    # æŒ‡å®šè¦è¿è¡Œçš„çˆ¬è™«åå­— (å’Œ spiders/arxiv.py é‡Œçš„ name ä¸€è‡´)
    process.crawl("arxiv")
    
    process.start()
    print("=== âœ… çˆ¬å–ä»»åŠ¡ç»“æŸ ===")